{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3fcc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch, os, sys\n",
    "# sys.path.append('/Users/sherryan/Desktop/cage_data/')\n",
    "# print(sys.path)\n",
    "import cage_data\n",
    "import numpy as np\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff27646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /Users/andrewshen/Desktop/neural_decoding/data/pickle_files/Pop_20210709_Cage_004.pkl is going to be loaded\n"
     ]
    }
   ],
   "source": [
    "# data_path = '/Users/sherryan/ssa-pop/'\n",
    "data_path = \"/Users/andrewshen/Desktop/neural_decoding/data/pickle_files/\"\n",
    "# files_name = ['Pop_20210709_Cage_001.pkl']\n",
    "files_name = [\"Pop_20210709_Cage_004.pkl\"]\n",
    "cage_data_list = []\n",
    "for file in files_name:\n",
    "    print('The file %s is going to be loaded'%(data_path + file))\n",
    "    with open ( data_path + file, 'rb' ) as fp:\n",
    "        cage_data = pickle.load(fp)\n",
    "        cage_data_list.append(cage_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618ddb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrew's code\n",
    "my_cage_data = cage_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a550a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a non-sorted file\n",
      "EMG filtered? -- False\n",
      "EMG filtered? -- False\n",
      "Cortical data cleaned? -- False\n",
      "Data binned? -- True\n",
      "Spikes smoothed? -- True\n"
     ]
    }
   ],
   "source": [
    "my_cage_data.pre_processing_summary()\n",
    "# We see that the spikes are smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f2576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9d6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = .025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f373d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bar_touch', 'treat_touch', 'pg_force_onset'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = cage_data.behave_event.keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693a3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_end_event(timing, cage_data):\n",
    "    timeframe = cage_data.binned['timeframe']\n",
    "    segment_range = np.where((timeframe>=timing-0.5) & (timeframe<=timing+1))[0]\n",
    "    start_idx = segment_range[0]\n",
    "    end_idx = segment_range[-1]\n",
    "    return start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c4ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_dict = {'crawl': [], 'precision': [], 'power': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89eebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrew's code\n",
    "\n",
    "# To get the binned spike counts\n",
    "binned_spike_counts = my_cage_data.binned['spikes']\n",
    "\n",
    "# To get the rectified, filtered and downsampled EMGs\n",
    "filtered_EMG = my_cage_data.binned['filtered_EMG']\n",
    "\n",
    "# To get the time frame of the binned data\n",
    "timeframe = my_cage_data.binned['timeframe']\n",
    "\n",
    "m1_data = np.transpose(binned_spike_counts)\n",
    "emg_data = np.transpose(filtered_EMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25a5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_spikes = []\n",
    "curr_idx = 0\n",
    "for key in keys:  \n",
    "    if key == 'bar_touch':\n",
    "        event = 'crawl'\n",
    "    if key == 'treat_touch':\n",
    "        event = 'precision'\n",
    "    if key == 'pg_force_onset':\n",
    "        event = 'power'\n",
    "    behav_dict[event].append(curr_idx)\n",
    "    for cage_data in cage_data_list:\n",
    "        spikes = np.array(cage_data.binned['spikes'])\n",
    "        for timing in cage_data.behave_event[key]:\n",
    "            start_idx, end_idx = find_start_end_event(timing, cage_data)\n",
    "            curr_idx += (end_idx - start_idx + 1)\n",
    "            concat_spikes.append(spikes[:,start_idx:end_idx+1])\n",
    "            behav_dict[event].append(curr_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d9773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 60, 95)\n",
      "(56, 60, 16)\n",
      "(56, 60)\n",
      "(31, 60, 95)\n",
      "(31, 60, 16)\n",
      "(31, 60)\n",
      "(11, 60, 95)\n",
      "(11, 60, 16)\n",
      "(11, 60)\n"
     ]
    }
   ],
   "source": [
    "# Andrew's code to keep only timestamps Set2 labeled behaviors for M1 and EMG\n",
    "\n",
    "m1_data_labeled_set2 = []\n",
    "emg_data_labeled_set2 = []\n",
    "behavioral_labels_set2 = []\n",
    "\n",
    "separate_modes = True\n",
    "trial_format = True\n",
    "num_bins = 1\n",
    "\n",
    "m1_data_labeled_set2_crawl = []\n",
    "emg_data_labeled_set2_crawl = []\n",
    "behavioral_labels_set2_crawl = []\n",
    "m1_data_labeled_set2_precision = []\n",
    "emg_data_labeled_set2_precision = []\n",
    "behavioral_labels_set2_precision = []\n",
    "m1_data_labeled_set2_power = []\n",
    "emg_data_labeled_set2_power = []\n",
    "behavioral_labels_set2_power = []\n",
    "\n",
    "concat_spikes = []\n",
    "curr_idx = 0\n",
    "for key in keys:  \n",
    "    if key == 'bar_touch':\n",
    "        event = 'crawl'\n",
    "    if key == 'treat_touch':\n",
    "        event = 'precision'\n",
    "    if key == 'pg_force_onset':\n",
    "        event = 'power'\n",
    "\n",
    "    behav_dict[event].append(curr_idx)\n",
    "    for cage_data in cage_data_list:\n",
    "        spikes = np.array(cage_data.binned['spikes'])\n",
    "        for timing in cage_data.behave_event[key]:\n",
    "            start_idx, end_idx = find_start_end_event(timing, cage_data)\n",
    "            curr_idx += (end_idx - start_idx + 1)\n",
    "            concat_spikes.append(spikes[:,start_idx:end_idx+1])\n",
    "\n",
    "            # Andrew's code\n",
    "            behavioral_label = event\n",
    "\n",
    "            # Add code to save data for separate modes\n",
    "            if separate_modes == False:\n",
    "\n",
    "                # Code to save timestamps without being split into trials\n",
    "                for i in range(start_idx, end_idx+1):\n",
    "                    if len(m1_data_labeled_set2) == 0:\n",
    "                        m1_data_labeled_set2 = np.array(m1_data[i+1-num_bins:i+1])\n",
    "                        emg_data_labeled_set2 = np.array(emg_data[i+1-num_bins:i+1])\n",
    "                        behavioral_labels_set2 = np.array([behavioral_label] * num_bins)\n",
    "                    else:\n",
    "                        m1_data_labeled_set2 = np.concatenate((m1_data_labeled_set2, m1_data[i+1-num_bins:i+1]))\n",
    "                        emg_data_labeled_set2 = np.concatenate((emg_data_labeled_set2, emg_data[i+1-num_bins:i+1]))\n",
    "                        behavioral_labels_set2 = np.concatenate((behavioral_labels_set2, [behavioral_label] * num_bins))\n",
    "\n",
    "                # Original code to save only timestamps with behavioral labels (new code should work with any bin size)\n",
    "                # if len(m1_data_labeled_set2) == 0:\n",
    "                #     m1_data_labeled_set2 = m1_data[start_idx:end_idx+1]\n",
    "                #     emg_data_labeled_set2 = emg_data[start_idx:end_idx+1]\n",
    "                #     behavioral_labels_set2 = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                # else:\n",
    "                #     m1_data_labeled_set2 = np.concatenate((m1_data_labeled_set2, m1_data[start_idx:end_idx+1]))\n",
    "                #     emg_data_labeled_set2 = np.concatenate((emg_data_labeled_set2, emg_data[start_idx:end_idx+1]))\n",
    "                #     behavioral_labels_set2 = np.concatenate((behavioral_labels_set2, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "\n",
    "            else:\n",
    "                if behavioral_label == \"crawl\":\n",
    "                    if len(m1_data_labeled_set2_crawl) == 0:\n",
    "                        m1_data_labeled_set2_crawl = m1_data[start_idx:end_idx+1]\n",
    "                        emg_data_labeled_set2_crawl = emg_data[start_idx:end_idx+1]\n",
    "                        behavioral_labels_set2_crawl = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                    else:\n",
    "                        m1_data_labeled_set2_crawl = np.concatenate((m1_data_labeled_set2_crawl, m1_data[start_idx:end_idx+1]))\n",
    "                        emg_data_labeled_set2_crawl = np.concatenate((emg_data_labeled_set2_crawl, emg_data[start_idx:end_idx+1]))\n",
    "                        behavioral_labels_set2_crawl = np.concatenate((behavioral_labels_set2_crawl, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "                elif behavioral_label == \"precision\":\n",
    "                    if len(m1_data_labeled_set2_precision) == 0:\n",
    "                        m1_data_labeled_set2_precision = m1_data[start_idx:end_idx+1]\n",
    "                        emg_data_labeled_set2_precision = emg_data[start_idx:end_idx+1]\n",
    "                        behavioral_labels_set2_precision = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                    else:\n",
    "                        m1_data_labeled_set2_precision = np.concatenate((m1_data_labeled_set2_precision, m1_data[start_idx:end_idx+1]))\n",
    "                        emg_data_labeled_set2_precision = np.concatenate((emg_data_labeled_set2_precision, emg_data[start_idx:end_idx+1]))\n",
    "                        behavioral_labels_set2_precision = np.concatenate((behavioral_labels_set2_precision, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "                elif behavioral_label == \"power\":\n",
    "                    if len(m1_data_labeled_set2_power) == 0:\n",
    "                        m1_data_labeled_set2_power = m1_data[start_idx:end_idx+1]\n",
    "                        emg_data_labeled_set2_power = emg_data[start_idx:end_idx+1]\n",
    "                        behavioral_labels_set2_power = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                    else:\n",
    "                        m1_data_labeled_set2_power = np.concatenate((m1_data_labeled_set2_power, m1_data[start_idx:end_idx+1]))\n",
    "                        emg_data_labeled_set2_power = np.concatenate((emg_data_labeled_set2_power, emg_data[start_idx:end_idx+1]))\n",
    "                        behavioral_labels_set2_power = np.concatenate((behavioral_labels_set2_power, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "\n",
    "\n",
    "# Save M1, EMG, and Set2 behavioral labels\n",
    "out_path = \"/Users/andrewshen/Desktop/neural_decoding/data/\"\n",
    "if separate_modes == False:\n",
    "    if trial_format:\n",
    "        m1_data_labeled_set2 = np.reshape(m1_data_labeled_set2, (m1_data_labeled_set2.shape[0]//(60*num_bins), 60*num_bins, m1_data_labeled_set2.shape[1]))\n",
    "        emg_data_labeled_set2 = np.reshape(emg_data_labeled_set2, (emg_data_labeled_set2.shape[0]//(60*num_bins), 60*num_bins, emg_data_labeled_set2.shape[1]))\n",
    "        behavioral_labels_set2 = np.reshape(behavioral_labels_set2, (behavioral_labels_set2.shape[0]//(60*num_bins), 60*num_bins))\n",
    "    np.save(out_path + \"set2_data/m1_set2\", m1_data_labeled_set2)\n",
    "    np.save(out_path + \"set2_data/emg_set2\", emg_data_labeled_set2)\n",
    "    np.save(out_path + \"set2_data/behavioral_set2\", behavioral_labels_set2)\n",
    "\n",
    "    print(m1_data_labeled_set2.shape)\n",
    "    print(emg_data_labeled_set2.shape)\n",
    "    print(behavioral_labels_set2.shape)\n",
    "\n",
    "else:\n",
    "    if trial_format:\n",
    "        m1_data_labeled_set2_crawl = np.reshape(m1_data_labeled_set2_crawl, (m1_data_labeled_set2_crawl.shape[0]//(60*num_bins), 60*num_bins, m1_data_labeled_set2_crawl.shape[1]))\n",
    "        emg_data_labeled_set2_crawl = np.reshape(emg_data_labeled_set2_crawl, (emg_data_labeled_set2_crawl.shape[0]//(60*num_bins), 60*num_bins, emg_data_labeled_set2_crawl.shape[1]))\n",
    "        behavioral_labels_set2_crawl = np.reshape(behavioral_labels_set2_crawl, (behavioral_labels_set2_crawl.shape[0]//(60*num_bins), 60*num_bins))\n",
    "        m1_data_labeled_set2_precision = np.reshape(m1_data_labeled_set2_precision, (m1_data_labeled_set2_precision.shape[0]//(60*num_bins), 60*num_bins, m1_data_labeled_set2_precision.shape[1]))\n",
    "        emg_data_labeled_set2_precision = np.reshape(emg_data_labeled_set2_precision, (emg_data_labeled_set2_precision.shape[0]//(60*num_bins), 60*num_bins, emg_data_labeled_set2_precision.shape[1]))\n",
    "        behavioral_labels_set2_precision = np.reshape(behavioral_labels_set2_precision, (behavioral_labels_set2_precision.shape[0]//(60*num_bins), 60*num_bins))\n",
    "        m1_data_labeled_set2_power = np.reshape(m1_data_labeled_set2_power, (m1_data_labeled_set2_power.shape[0]//(60*num_bins), 60*num_bins, m1_data_labeled_set2_power.shape[1]))\n",
    "        emg_data_labeled_set2_power = np.reshape(emg_data_labeled_set2_power, (emg_data_labeled_set2_power.shape[0]//(60*num_bins), 60*num_bins, emg_data_labeled_set2_power.shape[1]))\n",
    "        behavioral_labels_set2_power = np.reshape(behavioral_labels_set2_power, (behavioral_labels_set2_power.shape[0]//(60*num_bins), 60*num_bins))\n",
    "    np.save(out_path + \"set2_data/m1_set2_crawl\", m1_data_labeled_set2_crawl)\n",
    "    np.save(out_path + \"set2_data/emg_set2_crawl\", emg_data_labeled_set2_crawl)\n",
    "    np.save(out_path + \"set2_data/behavioral_set2_crawl\", behavioral_labels_set2_crawl)\n",
    "    np.save(out_path + \"set2_data/m1_set2_precision\", m1_data_labeled_set2_precision)\n",
    "    np.save(out_path + \"set2_data/emg_set2_precision\", emg_data_labeled_set2_precision)\n",
    "    np.save(out_path + \"set2_data/behavioral_set2_precision\", behavioral_labels_set2_precision)\n",
    "    np.save(out_path + \"set2_data/m1_set2_power\", m1_data_labeled_set2_power)\n",
    "    np.save(out_path + \"set2_data/emg_set2_power\", emg_data_labeled_set2_power)\n",
    "    np.save(out_path + \"set2_data/behavioral_set2_power\", behavioral_labels_set2_power)\n",
    "\n",
    "    print(m1_data_labeled_set2_crawl.shape)\n",
    "    print(emg_data_labeled_set2_crawl.shape)\n",
    "    print(behavioral_labels_set2_crawl.shape)\n",
    "    print(m1_data_labeled_set2_precision.shape)\n",
    "    print(emg_data_labeled_set2_precision.shape)\n",
    "    print(behavioral_labels_set2_precision.shape)\n",
    "    print(m1_data_labeled_set2_power.shape)\n",
    "    print(emg_data_labeled_set2_power.shape)\n",
    "    print(behavioral_labels_set2_power.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a6ddef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crawl': [0,\n",
       "  60,\n",
       "  120,\n",
       "  180,\n",
       "  240,\n",
       "  300,\n",
       "  360,\n",
       "  420,\n",
       "  480,\n",
       "  540,\n",
       "  600,\n",
       "  660,\n",
       "  720,\n",
       "  780,\n",
       "  840,\n",
       "  900,\n",
       "  960,\n",
       "  1020,\n",
       "  1080,\n",
       "  1140,\n",
       "  1200,\n",
       "  1260,\n",
       "  1320,\n",
       "  1380,\n",
       "  1440,\n",
       "  1500,\n",
       "  1560,\n",
       "  1620,\n",
       "  1680,\n",
       "  1740,\n",
       "  1800,\n",
       "  1860,\n",
       "  1920,\n",
       "  1980,\n",
       "  2040,\n",
       "  2100,\n",
       "  2160,\n",
       "  2220,\n",
       "  2280,\n",
       "  2340,\n",
       "  2400,\n",
       "  2460,\n",
       "  2520,\n",
       "  2580,\n",
       "  2640,\n",
       "  2700,\n",
       "  2760,\n",
       "  2820,\n",
       "  2880,\n",
       "  2940,\n",
       "  3000,\n",
       "  3060,\n",
       "  3120,\n",
       "  3180,\n",
       "  3240,\n",
       "  3300,\n",
       "  3360],\n",
       " 'precision': [3360,\n",
       "  3420,\n",
       "  3480,\n",
       "  3540,\n",
       "  3600,\n",
       "  3660,\n",
       "  3720,\n",
       "  3780,\n",
       "  3840,\n",
       "  3900,\n",
       "  3960,\n",
       "  4020,\n",
       "  4080,\n",
       "  4140,\n",
       "  4200,\n",
       "  4260,\n",
       "  4320,\n",
       "  4380,\n",
       "  4440,\n",
       "  4500,\n",
       "  4560,\n",
       "  4620,\n",
       "  4680,\n",
       "  4740,\n",
       "  4800,\n",
       "  4860,\n",
       "  4920,\n",
       "  4980,\n",
       "  5040,\n",
       "  5100,\n",
       "  5160,\n",
       "  5220],\n",
       " 'power': [5220,\n",
       "  5280,\n",
       "  5340,\n",
       "  5400,\n",
       "  5460,\n",
       "  5520,\n",
       "  5580,\n",
       "  5640,\n",
       "  5700,\n",
       "  5760,\n",
       "  5820,\n",
       "  5880]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
