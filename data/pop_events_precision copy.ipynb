{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f3fcc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch, os, sys\n",
    "# sys.path.append('/Users/sherryan/Desktop/cage_data/')\n",
    "# print(sys.path)\n",
    "import cage_data\n",
    "import numpy as np\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ff27646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /Users/andrewshen/Github_Repos/neural_decoding/data/pickle_files/Pop_20210709_Cage_004.pkl is going to be loaded\n"
     ]
    }
   ],
   "source": [
    "# data_path = '/Users/sherryan/ssa-pop/'\n",
    "curr_dir = os.getcwd()\n",
    "data_path = \"%s/pickle_files/\" % curr_dir\n",
    "# files_name = ['Pop_20210709_Cage_001.pkl']\n",
    "files_name = [\"Pop_20210709_Cage_004.pkl\"]\n",
    "cage_data_list = []\n",
    "for file in files_name:\n",
    "    print('The file %s is going to be loaded'%(data_path + file))\n",
    "    with open ( data_path + file, 'rb' ) as fp:\n",
    "        cage_data = pickle.load(fp)\n",
    "        cage_data_list.append(cage_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618ddb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrew's code\n",
    "my_cage_data = cage_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a550a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a non-sorted file\n",
      "EMG filtered? -- False\n",
      "EMG filtered? -- False\n",
      "Cortical data cleaned? -- False\n",
      "Data binned? -- True\n",
      "Spikes smoothed? -- True\n"
     ]
    }
   ],
   "source": [
    "my_cage_data.pre_processing_summary()\n",
    "# We see that the spikes are smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f2576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b9d6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = .025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f373d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bar_touch', 'treat_touch', 'pg_force_onset'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = cage_data.behave_event.keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "693a3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_start_end_event(timing, cage_data):\n",
    "    timeframe = cage_data.binned['timeframe']\n",
    "    segment_range = np.where((timeframe>=timing-0.5) & (timeframe<=timing+2))[0] # Changed for expanded time range\n",
    "    start_idx = segment_range[0]\n",
    "    end_idx = segment_range[-1]\n",
    "    return start_idx, end_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77c4ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_dict = {'crawl': [], 'precision': [], 'power': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a89eebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrew's code\n",
    "\n",
    "# To get the binned spike counts\n",
    "binned_spike_counts = my_cage_data.binned['spikes']\n",
    "\n",
    "# To get the rectified, filtered and downsampled EMGs\n",
    "filtered_EMG = my_cage_data.binned['filtered_EMG']\n",
    "\n",
    "# To get the time frame of the binned data\n",
    "timeframe = my_cage_data.binned['timeframe']\n",
    "\n",
    "m1_data = np.transpose(binned_spike_counts)\n",
    "emg_data = np.transpose(filtered_EMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f25a5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_length = None # For splitting into trials at the end\n",
    "\n",
    "concat_spikes = []\n",
    "curr_idx = 0\n",
    "for key in keys:  \n",
    "    if key == 'bar_touch':\n",
    "        event = 'crawl'\n",
    "    if key == 'treat_touch':\n",
    "        event = 'precision'\n",
    "    if key == 'pg_force_onset':\n",
    "        event = 'power'\n",
    "    behav_dict[event].append(curr_idx)\n",
    "    for cage_data in cage_data_list:\n",
    "        spikes = np.array(cage_data.binned['spikes'])\n",
    "        for timing in cage_data.behave_event[key]:\n",
    "            start_idx, end_idx = find_start_end_event(timing, cage_data)\n",
    "            trial_length = end_idx-start_idx+1\n",
    "            curr_idx += (end_idx - start_idx + 1)\n",
    "            concat_spikes.append(spikes[:,start_idx:end_idx+1])\n",
    "            behav_dict[event].append(curr_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29d9773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 100, 95)\n",
      "(98, 100, 16)\n",
      "(98, 100)\n"
     ]
    }
   ],
   "source": [
    "# Andrew's code to keep only timestamps Set2 labeled behaviors for M1 and EMG\n",
    "\n",
    "m1_data_labeled_set2 = []\n",
    "emg_data_labeled_set2 = []\n",
    "behavioral_labels_set2 = []\n",
    "\n",
    "separate_modes = False\n",
    "trial_format = True\n",
    "num_bins = 1\n",
    "\n",
    "m1_data_labeled_set2_crawl = []\n",
    "emg_data_labeled_set2_crawl = []\n",
    "behavioral_labels_set2_crawl = []\n",
    "m1_data_labeled_set2_precision = []\n",
    "emg_data_labeled_set2_precision = []\n",
    "behavioral_labels_set2_precision = []\n",
    "m1_data_labeled_set2_power = []\n",
    "emg_data_labeled_set2_power = []\n",
    "behavioral_labels_set2_power = []\n",
    "\n",
    "concat_spikes = []\n",
    "curr_idx = 0\n",
    "for key in keys:  \n",
    "    if key == 'bar_touch':\n",
    "        event = 'crawl'\n",
    "    if key == 'treat_touch':\n",
    "        event = 'precision'\n",
    "    if key == 'pg_force_onset':\n",
    "        event = 'power'\n",
    "\n",
    "    behav_dict[event].append(curr_idx)\n",
    "    for cage_data in cage_data_list:\n",
    "        spikes = np.array(cage_data.binned['spikes'])\n",
    "        for timing in cage_data.behave_event[key]:\n",
    "            start_idx, end_idx = find_start_end_event(timing, cage_data)\n",
    "            curr_idx += (end_idx - start_idx + 1)\n",
    "            concat_spikes.append(spikes[:,start_idx:end_idx+1])\n",
    "\n",
    "            # Andrew's code\n",
    "            behavioral_label = event\n",
    "\n",
    "            # Add code to save data for separate modes\n",
    "            if separate_modes == False:\n",
    "\n",
    "                # Code to save timestamps without being split into trials\n",
    "                for i in range(start_idx, end_idx+1):\n",
    "                    if len(m1_data_labeled_set2) == 0:\n",
    "                        m1_data_labeled_set2 = np.array(np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0))\n",
    "                        emg_data_labeled_set2 = np.array(np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0))\n",
    "                        behavioral_labels_set2 = np.array([behavioral_label])\n",
    "                    else:\n",
    "                        m1_data_labeled_set2 = np.concatenate((m1_data_labeled_set2, np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                        emg_data_labeled_set2 = np.concatenate((emg_data_labeled_set2, np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                        behavioral_labels_set2 = np.concatenate((behavioral_labels_set2, [behavioral_label]))\n",
    "\n",
    "                # Original code to save only timestamps with behavioral labels (new code should work with any bin size)\n",
    "                # if len(m1_data_labeled_set2) == 0:\n",
    "                #     m1_data_labeled_set2 = m1_data[start_idx:end_idx+1]\n",
    "                #     emg_data_labeled_set2 = emg_data[start_idx:end_idx+1]\n",
    "                #     behavioral_labels_set2 = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                # else:\n",
    "                #     m1_data_labeled_set2 = np.concatenate((m1_data_labeled_set2, m1_data[start_idx:end_idx+1]))\n",
    "                #     emg_data_labeled_set2 = np.concatenate((emg_data_labeled_set2, emg_data[start_idx:end_idx+1]))\n",
    "                #     behavioral_labels_set2 = np.concatenate((behavioral_labels_set2, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "\n",
    "            elif separate_modes == True:\n",
    "                if behavioral_label == \"crawl\":\n",
    "                    for i in range(start_idx, end_idx+1):\n",
    "                        if len(m1_data_labeled_set2_crawl) == 0:\n",
    "                            m1_data_labeled_set2_crawl = np.array(np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0))\n",
    "                            emg_data_labeled_set2_crawl = np.array(np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0))\n",
    "                            behavioral_labels_set2_crawl = np.array([behavioral_label])\n",
    "                        else:\n",
    "                            m1_data_labeled_set2_crawl = np.concatenate((m1_data_labeled_set2_crawl, np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                            emg_data_labeled_set2_crawl = np.concatenate((emg_data_labeled_set2_crawl, np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                            behavioral_labels_set2_crawl = np.concatenate((behavioral_labels_set2_crawl, [behavioral_label]))\n",
    "                \n",
    "                elif behavioral_label == \"precision\":\n",
    "                    for i in range(start_idx, end_idx+1):\n",
    "                        if len(m1_data_labeled_set2_precision) == 0:\n",
    "                            m1_data_labeled_set2_precision = np.array(np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0))\n",
    "                            emg_data_labeled_set2_precision = np.array(np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0))\n",
    "                            behavioral_labels_set2_precision = np.array([behavioral_label])\n",
    "                        else:\n",
    "                            m1_data_labeled_set2_precision = np.concatenate((m1_data_labeled_set2_precision, np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                            emg_data_labeled_set2_precision = np.concatenate((emg_data_labeled_set2_precision, np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                            behavioral_labels_set2_precision = np.concatenate((behavioral_labels_set2_precision, [behavioral_label]))\n",
    "\n",
    "                if behavioral_label == \"power\":\n",
    "                    for i in range(start_idx, end_idx+1):\n",
    "                        if len(m1_data_labeled_set2_power) == 0:\n",
    "                            m1_data_labeled_set2_power = np.array(np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0))\n",
    "                            emg_data_labeled_set2_power = np.array(np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0))\n",
    "                            behavioral_labels_set2_power = np.array([behavioral_label])\n",
    "                        else:\n",
    "                            m1_data_labeled_set2_power = np.concatenate((m1_data_labeled_set2_power, np.expand_dims(np.concatenate(m1_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                            emg_data_labeled_set2_power = np.concatenate((emg_data_labeled_set2_power, np.expand_dims(np.concatenate(emg_data[i+1-num_bins:i+1]), axis=0)))\n",
    "                            behavioral_labels_set2_power = np.concatenate((behavioral_labels_set2_power, [behavioral_label]))\n",
    "\n",
    "                # Original code\n",
    "                # if behavioral_label == \"crawl\":\n",
    "                #     if len(m1_data_labeled_set2_crawl) == 0:\n",
    "                #         m1_data_labeled_set2_crawl = m1_data[start_idx:end_idx+1]\n",
    "                #         emg_data_labeled_set2_crawl = emg_data[start_idx:end_idx+1]\n",
    "                #         behavioral_labels_set2_crawl = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                #     else:\n",
    "                #         m1_data_labeled_set2_crawl = np.concatenate((m1_data_labeled_set2_crawl, m1_data[start_idx:end_idx+1]))\n",
    "                #         emg_data_labeled_set2_crawl = np.concatenate((emg_data_labeled_set2_crawl, emg_data[start_idx:end_idx+1]))\n",
    "                #         behavioral_labels_set2_crawl = np.concatenate((behavioral_labels_set2_crawl, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "                # elif behavioral_label == \"precision\":\n",
    "                #     if len(m1_data_labeled_set2_precision) == 0:\n",
    "                #         m1_data_labeled_set2_precision = m1_data[start_idx:end_idx+1]\n",
    "                #         emg_data_labeled_set2_precision = emg_data[start_idx:end_idx+1]\n",
    "                #         behavioral_labels_set2_precision = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                #     else:\n",
    "                #         m1_data_labeled_set2_precision = np.concatenate((m1_data_labeled_set2_precision, m1_data[start_idx:end_idx+1]))\n",
    "                #         emg_data_labeled_set2_precision = np.concatenate((emg_data_labeled_set2_precision, emg_data[start_idx:end_idx+1]))\n",
    "                #         behavioral_labels_set2_precision = np.concatenate((behavioral_labels_set2_precision, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "                # elif behavioral_label == \"power\":\n",
    "                #     if len(m1_data_labeled_set2_power) == 0:\n",
    "                #         m1_data_labeled_set2_power = m1_data[start_idx:end_idx+1]\n",
    "                #         emg_data_labeled_set2_power = emg_data[start_idx:end_idx+1]\n",
    "                #         behavioral_labels_set2_power = np.array([behavioral_label for i in range(end_idx-start_idx+1)])\n",
    "                #     else:\n",
    "                #         m1_data_labeled_set2_power = np.concatenate((m1_data_labeled_set2_power, m1_data[start_idx:end_idx+1]))\n",
    "                #         emg_data_labeled_set2_power = np.concatenate((emg_data_labeled_set2_power, emg_data[start_idx:end_idx+1]))\n",
    "                #         behavioral_labels_set2_power = np.concatenate((behavioral_labels_set2_power, np.array([behavioral_label for i in range(end_idx-start_idx+1)])))\n",
    "\n",
    "# Save M1, EMG, and Set2 behavioral labels\n",
    "out_path = \"/Users/andrewshen/Desktop/neural_decoding/data/\"\n",
    "if separate_modes == False:\n",
    "    # Format into trials\n",
    "    if trial_format:\n",
    "        m1_data_labeled_set2 = np.reshape(m1_data_labeled_set2, (m1_data_labeled_set2.shape[0]//(trial_length), trial_length, m1_data_labeled_set2.shape[1]))\n",
    "        emg_data_labeled_set2 = np.reshape(emg_data_labeled_set2, (emg_data_labeled_set2.shape[0]//(trial_length), trial_length, emg_data_labeled_set2.shape[1]))\n",
    "        behavioral_labels_set2 = np.reshape(behavioral_labels_set2, (behavioral_labels_set2.shape[0]//(trial_length), trial_length))\n",
    "    # np.save(out_path + \"set2_data/m1_set2_t100_b10\", m1_data_labeled_set2)\n",
    "    # np.save(out_path + \"set2_data/emg_set2_t100_b10\", emg_data_labeled_set2)\n",
    "    # np.save(out_path + \"set2_data/behavioral_set2_t100_b10\", behavioral_labels_set2)\n",
    "\n",
    "    print(m1_data_labeled_set2.shape)\n",
    "    print(emg_data_labeled_set2.shape)\n",
    "    print(behavioral_labels_set2.shape)\n",
    "\n",
    "elif separate_modes == True:\n",
    "\n",
    "    # Format into trials\n",
    "    if trial_format:\n",
    "        m1_data_labeled_set2_crawl = np.reshape(m1_data_labeled_set2_crawl, (m1_data_labeled_set2_crawl.shape[0]//(trial_length), trial_length, m1_data_labeled_set2_crawl.shape[1]))\n",
    "        emg_data_labeled_set2_crawl = np.reshape(emg_data_labeled_set2_crawl, (emg_data_labeled_set2_crawl.shape[0]//(trial_length), trial_length, emg_data_labeled_set2_crawl.shape[1]))\n",
    "        behavioral_labels_set2_crawl = np.reshape(behavioral_labels_set2_crawl, (behavioral_labels_set2_crawl.shape[0]//(trial_length), trial_length))\n",
    "        m1_data_labeled_set2_precision = np.reshape(m1_data_labeled_set2_precision, (m1_data_labeled_set2_precision.shape[0]//(trial_length), trial_length, m1_data_labeled_set2_precision.shape[1]))\n",
    "        emg_data_labeled_set2_precision = np.reshape(emg_data_labeled_set2_precision, (emg_data_labeled_set2_precision.shape[0]//(trial_length), trial_length, emg_data_labeled_set2_precision.shape[1]))\n",
    "        behavioral_labels_set2_precision = np.reshape(behavioral_labels_set2_precision, (behavioral_labels_set2_precision.shape[0]//(trial_length), trial_length))\n",
    "        m1_data_labeled_set2_power = np.reshape(m1_data_labeled_set2_power, (m1_data_labeled_set2_power.shape[0]//(trial_length), trial_length, m1_data_labeled_set2_power.shape[1]))\n",
    "        emg_data_labeled_set2_power = np.reshape(emg_data_labeled_set2_power, (emg_data_labeled_set2_power.shape[0]//(trial_length), trial_length, emg_data_labeled_set2_power.shape[1]))\n",
    "        behavioral_labels_set2_power = np.reshape(behavioral_labels_set2_power, (behavioral_labels_set2_power.shape[0]//(trial_length), trial_length))\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/m1_set2_t100_b10_crawl\", m1_data_labeled_set2_crawl)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/emg_set2_t100_b10_crawl\", emg_data_labeled_set2_crawl)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/behavioral_set2_t100_b10_crawl\", behavioral_labels_set2_crawl)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/m1_set2_t100_b10_precision\", m1_data_labeled_set2_precision)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/emg_set2_t100_b10_precision\", emg_data_labeled_set2_precision)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/behavioral_set2_t100_b10_precision\", behavioral_labels_set2_precision)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/m1_set2_t100_b10_power\", m1_data_labeled_set2_power)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/emg_set2_t100_b10_power\", emg_data_labeled_set2_power)\n",
    "    # np.save(out_path + \"set2_data/sep_modes_b10/behavioral_set2_t100_b10_power\", behavioral_labels_set2_power)\n",
    "\n",
    "    print(m1_data_labeled_set2_crawl.shape)\n",
    "    print(emg_data_labeled_set2_crawl.shape)\n",
    "    print(behavioral_labels_set2_crawl.shape)\n",
    "    print(m1_data_labeled_set2_precision.shape)\n",
    "    print(emg_data_labeled_set2_precision.shape)\n",
    "    print(behavioral_labels_set2_precision.shape)\n",
    "    print(m1_data_labeled_set2_power.shape)\n",
    "    print(emg_data_labeled_set2_power.shape)\n",
    "    print(behavioral_labels_set2_power.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
